{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd90d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4322591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Configuration\n",
    "def load_config(path='config.json'):\n",
    "    if not os.path.exists(path):\n",
    "     raise FileNotFoundError(f\"Configuration file not found at {path}\")\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c038f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data from csv\n",
    "def read_raw(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    if file_path.lower().endswith(\".csv\"):\n",
    "        try:\n",
    "            return pd.read_csv(file_path, low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            return pd.read_csv(file_path, encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "    elif file_path.lower().endswith(\".xlsx\") or file_path.lower().endswith(\".xls\"):\n",
    "        return pd.read_excel(file_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use CSV or Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2742c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_invoice_date(df):\n",
    "    # common date column names\n",
    "    possible_cols = [\"InvoiceDate\", \"invoice_date\", \"Invoice Date\", \"Date\"]\n",
    "\n",
    "    for col in possible_cols:\n",
    "        if col in df.columns:\n",
    "            df[\"invoice_date\"] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            return df\n",
    "\n",
    "    # fallback: try to detect automatically\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            try:\n",
    "                df[\"invoice_date\"] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "                return df\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # if still not found\n",
    "    df[\"invoice_date\"] = pd.NaT\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8927c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize columns name to lower case and replace spaces with underscores\n",
    "\n",
    "def normalize_columns(df):\n",
    "    col_map = {}\n",
    "    for c in df.columns:\n",
    "        lc = c.lower().replace(\" \",\"\")\n",
    "        if lc in (\"invoiceno\",\"invoice\"):\n",
    "            col_map[c] =\"invoice_no\"\n",
    "        if lc == \"quantity\":\n",
    "            col_map[c] =\"quantity\"\n",
    "        if lc in (\"unitprice\",\"unit_price\"):\n",
    "            col_map[c] = \"unit_price\"\n",
    "        if lc in (\"description\",\"product\",\"productname\"):\n",
    "            col_map[c] = \"description\"\n",
    "        if lc == \"country\":\n",
    "            col_map[c] = \"country\"\n",
    "    return df.rename(columns=col_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3afe0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(df):\n",
    "    # Fix quantity column\n",
    "    if \"quantity\" in df.columns:\n",
    "        df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], errors='coerce').fillna(0).astype(int)\n",
    "    else:\n",
    "        df[\"quantity\"] = 0\n",
    "\n",
    "    # Fix unit_price column\n",
    "    if \"unit_price\" in df.columns:\n",
    "        df[\"unit_price\"] = pd.to_numeric(df[\"unit_price\"], errors='coerce').fillna(0.0)\n",
    "    else:\n",
    "        df[\"unit_price\"] = 0.0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e8f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_revenue(df, simulate_cost_pct=0.6):\n",
    "    df[\"revenue\"] = df[\"quantity\"] * df[\"unit_price\"]\n",
    "    df[\"cost_per_unit\"] = df[\"unit_price\"] * simulate_cost_pct\n",
    "    df[\"total_cost\"] = df[\"cost_per_unit\"] * df[\"quantity\"]\n",
    "    df[\"profit\"] = df[\"revenue\"] - df[\"total_cost\"]\n",
    "\n",
    "    # create invoice_date_only safely\n",
    "    if \"invoice_date\" in df.columns:\n",
    "        df[\"invoice_date_only\"] = pd.to_datetime(df[\"invoice_date\"].dt.date)\n",
    "    else:\n",
    "        raise ValueError(\"invoice_date is missing. Cannot create invoice_date_only.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f991236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we delete duplicate\n",
    "def duplicates(df):\n",
    "    if \"invoice_no\" in df.columns and  \"quantity\" in df.columns:\n",
    "\n",
    "        df =df.drop_duplicates(subset=[\"invoice_no\",\"quantity\"])\n",
    "    else:\n",
    "        df = df.drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4b0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_kpis(df):\n",
    "    \"\"\"\n",
    "    Create daily KPI summary from cleaned transaction data.\n",
    "\n",
    "    Requires in df:\n",
    "      - 'invoice_date_only' (date per row)\n",
    "      - 'revenue' (numeric)\n",
    "      - optionally 'invoice_no' (for order count)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # safety checks\n",
    "    if \"invoice_date_only\" not in df.columns:\n",
    "        raise ValueError(\"invoice_date_only is missing. Run derive_revenue() before compute_daily_kpis().\")\n",
    "    if \"revenue\" not in df.columns:\n",
    "        raise ValueError(\"revenue column is missing. Make sure derive_revenue() created it.\")\n",
    "\n",
    "    # make sure date-only is treated as date\n",
    "    df[\"invoice_date_only\"] = pd.to_datetime(df[\"invoice_date_only\"]).dt.date\n",
    "\n",
    "    # group by day\n",
    "    kpi = (\n",
    "        df.groupby(\"invoice_date_only\")\n",
    "          .agg(\n",
    "              total_revenue=(\"revenue\", \"sum\"),\n",
    "              total_orders=(\"invoice_no\", lambda s: s.nunique() if \"invoice_no\" in df.columns else len(s))\n",
    "          )\n",
    "          .reset_index()\n",
    "          .sort_values(\"invoice_date_only\")\n",
    "    )\n",
    "\n",
    "    # previous day's revenue\n",
    "    kpi[\"prev_revenue\"] = kpi[\"total_revenue\"].shift(1)\n",
    "\n",
    "    # safe percent change (avoid divide by zero)\n",
    "    kpi[\"revenue_change_pct\"] = 0.0\n",
    "    mask = kpi[\"prev_revenue\"].notna() & (kpi[\"prev_revenue\"] != 0)\n",
    "    kpi.loc[mask, \"revenue_change_pct\"] = (\n",
    "        (kpi.loc[mask, \"total_revenue\"] - kpi.loc[mask, \"prev_revenue\"])\n",
    "        / kpi.loc[mask, \"prev_revenue\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    return kpi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e40267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def save_csv(df_clean, kpi_df, folder=\"data/processed\"):\n",
    "    \"\"\"\n",
    "    Save cleaned transaction data and daily KPI summary to CSV files.\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # unique name per run\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    clean_path = os.path.join(folder, f\"sales_clean_{date_str}.csv\")\n",
    "    kpi_path  = os.path.join(folder, f\"daily_kpis_{date_str}.csv\")\n",
    "\n",
    "    df_clean.to_csv(clean_path, index=False)\n",
    "    kpi_df.to_csv(kpi_path, index=False)\n",
    "\n",
    "    print(f\"Cleaned data saved to: {clean_path}\")\n",
    "    print(f\"KPI data saved to:     {kpi_path}\")\n",
    "\n",
    "    return clean_path, kpi_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d20bf57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def save_kpi_to_mysql(kpi_df):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        port = 3306,\n",
    "        user=\"root\",\n",
    "        password=\"Rasik@2005\",\n",
    "        database=\"retail_etl\"\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    insert_sql = \"\"\"\n",
    "    INSERT INTO daily_kpis (invoice_date, total_revenue, total_orders, revenue_change_pct)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        total_revenue = VALUES(total_revenue),\n",
    "        total_orders = VALUES(total_orders),\n",
    "        revenue_change_pct = VALUES(revenue_change_pct);\n",
    "    \"\"\"\n",
    "\n",
    "    records = []\n",
    "    for _, row in kpi_df.iterrows():\n",
    "        records.append((\n",
    "            row[\"invoice_date_only\"],\n",
    "            row[\"total_revenue\"],\n",
    "            row[\"total_orders\"],\n",
    "            row[\"revenue_change_pct\"]\n",
    "        ))\n",
    "\n",
    "    cursor.executemany(insert_sql, records)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"KPI data saved to MySQL table 'daily_kpis'.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ca1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_alert_print(kpi_df, threshold):\n",
    "    \"\"\"\n",
    "    Print alerts when % revenue change exceeds +/- threshold.\n",
    "    threshold: percent drop or increase considered significant\n",
    "    \"\"\"\n",
    "    latest = kpi_df.iloc[-1]       # last date\n",
    "    prev = kpi_df.iloc[-2] if len(kpi_df) > 1 else None\n",
    "\n",
    "    change = latest[\"revenue_change_pct\"]\n",
    "\n",
    "    print(\"\\n>>> Alert Check\")\n",
    "    print(f\"Latest Date: {latest['invoice_date_only']}, Change: {change}%\")\n",
    "\n",
    "    if change <= -threshold:\n",
    "        print(f\"ðŸš¨ Sales dropped by {abs(change)}% vs previous day!\")\n",
    "    elif change >= threshold:\n",
    "        print(f\"ðŸ“ˆ Sales increased by {change}% vs previous day!\")\n",
    "    else:\n",
    "        print(\"âœ“ No major sales change detected.\")\n",
    "\n",
    "def main():\n",
    "    # Load config\n",
    "    config = load_config()\n",
    "\n",
    "    # Read raw data\n",
    "    raw_path = config.get(\"data_file\", \"data/raw/sales_data.csv\")\n",
    "    df_raw = read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ae7616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reading data\n",
      ">>> Parsing date\n",
      ">>> Normalizing columns\n",
      ">>> Cleaning numeric values\n",
      ">>> Calculating revenue & profit\n",
      ">>> Removing duplicates\n",
      ">>> Computing daily KPIs\n",
      ">>> Saving cleaned & KPI CSVs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patil\\AppData\\Local\\Temp\\ipykernel_24064\\2411217164.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"invoice_date_only\"] = pd.to_datetime(df[\"invoice_date_only\"]).dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: data/processed\\sales_clean_20251120_134813.csv\n",
      "KPI data saved to:     data/processed\\daily_kpis_20251120_134813.csv\n",
      ">>> Saving KPIs to MySQL\n",
      "KPI data saved to MySQL table 'daily_kpis'.\n",
      ">>> Checking alerts\n",
      "\n",
      ">>> Alert Check\n",
      "Latest Date: 2010-12-09, Change: 0.0%\n",
      "âœ“ No major sales change detected.\n",
      "\n",
      "Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def etl_process(config):\n",
    "    raw_csv          = config[\"raw_csv\"]\n",
    "    processed_folder = config[\"processed_folder\"]\n",
    "    threshold        = config[\"sales_drop_threshold_pct\"]\n",
    "\n",
    "    print(\">>> Reading data\")\n",
    "    df = read_raw(raw_csv)\n",
    "\n",
    "    print(\">>> Parsing date\")\n",
    "    df = parse_invoice_date(df)\n",
    "\n",
    "    print(\">>> Normalizing columns\")\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    print(\">>> Cleaning numeric values\")\n",
    "    df = clean_numeric(df)\n",
    "\n",
    "    print(\">>> Calculating revenue & profit\")\n",
    "    df_clean = derive_revenue(df)\n",
    "\n",
    "    print(\">>> Removing duplicates\")\n",
    "    df_clean = duplicates(df_clean)\n",
    "\n",
    "    print(\">>> Computing daily KPIs\")\n",
    "    kpi_df = compute_daily_kpis(df_clean)\n",
    "\n",
    "    print(\">>> Saving cleaned & KPI CSVs\")\n",
    "    save_csv(df_clean, kpi_df, processed_folder)\n",
    "\n",
    "    print(\">>> Saving KPIs to MySQL\")\n",
    "    save_kpi_to_mysql(kpi_df)   # ðŸ‘ˆ HERE we push to SQL\n",
    "\n",
    "    print(\">>> Checking alerts\")\n",
    "    check_alert_print(kpi_df, threshold)\n",
    "\n",
    "    print(\"\\nPipeline completed successfully!\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cfg = load_config()\n",
    "    etl_process(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381383c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cc468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
